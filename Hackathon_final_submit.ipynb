{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b8b79b4-2585-406a-a7e8-dbd2701123ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automated_modelling(input_file):\n",
    "    \n",
    "    # importing required Libraries\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    from striprtf.striprtf import rtf_to_text\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    import json\n",
    "    \n",
    "    # extract the text from rtf file and parse it as a JSON\n",
    "    with open(input_file, 'r') as f:\n",
    "        rtf_content = f.read()\n",
    "        plain_text = rtf_to_text(rtf_content)\n",
    "        dict = json.loads(plain_text)\n",
    "        # this result in a dictionary \n",
    "    \n",
    "    # read the csv as DataFrame\n",
    "    df = pd.read_csv(dict['design_state_data']['session_info']['dataset'])\n",
    "    \n",
    "    # target columns detail\n",
    "    problem_type = dict['design_state_data']['target']['prediction_type']\n",
    "    target_col = dict['design_state_data']['target']['target']\n",
    "    \n",
    "    # extract the columns name that is selected true\n",
    "    org_df_col = df.columns\n",
    "    is_false_col = []\n",
    "    \n",
    "    # looping into cols of DataFrame\n",
    "    for col in org_df_col:\n",
    "        if not dict['design_state_data']['feature_handling'][col]['is_selected']:\n",
    "            is_false_col.append(col)\n",
    "            \n",
    "    # drop not_selected_col:\n",
    "    df.drop(columns = is_false_col, inplace = True)\n",
    "    \n",
    "    # split the data frame into x and y\n",
    "    x = df.drop(columns = target_col).copy()\n",
    "    y = df[target_col].copy()\n",
    "    \n",
    "    # numeric columns and categorical columns in x\n",
    "    num_col_x = x.select_dtypes(exclude = 'O').columns\n",
    "    cat_col_x = x.select_dtypes(include = 'O').columns\n",
    "    \n",
    "    \n",
    "    # empty list for missing value imputation with method\n",
    "    avg_col = []\n",
    "    median_col = []\n",
    "    mode_col = []\n",
    "    std_scaling_col = []\n",
    "    min_max_scaling_col =[]\n",
    "    \n",
    "    for col in num_col_x:      \n",
    "        for key in dict['design_state_data']['feature_handling'][col]['feature_details']:\n",
    "            \n",
    "            if key == 'rescaling' and dict['design_state_data']['feature_handling'][col]['feature_details'][key] == 'MinMaxScaler':\n",
    "                min_max_scaling_col.append(col)\n",
    "                \n",
    "            elif key == 'rescaling' and dict['design_state_data']['feature_handling'][col]['feature_details'][key] == 'StandardScaler':\n",
    "                std_scaling_col.append(col)\n",
    "            \n",
    "            elif key == 'missing_values' and not dict['design_state_data']['feature_handling'][col]['feature_details'][key]:\n",
    "                continue\n",
    "            # if missing_values is false then loops\n",
    "            \n",
    "            elif key == 'impute_with' and dict['design_state_data']['feature_handling'][col]['feature_details'][key] == 'Average of values':\n",
    "                avg_col.append(col)\n",
    "                \n",
    "            elif key == 'impute_with' and dict['design_state_data']['feature_handling'][col]['feature_details'][key] == 'Median of values':\n",
    "                median_col.append(col)\n",
    "                \n",
    "            elif key == 'impute_with' and dict['design_state_data']['feature_handling'][col]['feature_details'][key] == 'Mode of values':\n",
    "                mode_col.append(col)\n",
    "            \n",
    "            \n",
    "    # performing Train_test_split\n",
    "    random_state = dict['design_state_data']['train']['random_seed']\n",
    "    train_size = dict['design_state_data']['train']['train_ratio']\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = tts(x,y, train_size = train_size, random_state = random_state)\n",
    "    \n",
    "    # define object of simpleimputer\n",
    "    si_mean = SimpleImputer(strategy = 'mean')\n",
    "    si_median = SimpleImputer(strategy = 'median')\n",
    "    si_mode = SimpleImputer(strategy = 'most_frequent')\n",
    "    \n",
    "    # impute missing values \n",
    "    \n",
    "    if len(avg_col) > 0:\n",
    "        x_train[avg_col] = si_mean.fit_transform(x_train[avg_col])\n",
    "        x_test[avg_col]  = si_mean.transform(x_test[avg_col])\n",
    "    \n",
    "    if len(median_col) > 0:\n",
    "        x_train[median_col] = si_median.fit_transform(x_train[median_col])\n",
    "        x_test[median_col]  = si_median.transform(x_test[median_col])\n",
    "        \n",
    "    if len(mode_col) > 0:\n",
    "        x_train[mode_col] = si_mode.fit_transform(x_train[mode_col])\n",
    "        x_test[mode_col]  = si_mode.transform(x_test[mode_col])\n",
    "        \n",
    "   \n",
    "    # defining scaling methods i.e, minmax scaler and standard scaler \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    std_scaler = StandardScaler()\n",
    "    \n",
    "    # rescaling the features \n",
    "    if len(std_scaling_col) > 0:\n",
    "        x_train[std_scaling_col] = std_scaler.fit_transform(x_train[std_scaling_col])\n",
    "        x_test[std_scaling_col]  = std_scaler.transform(x_test[std_scaling_col])\n",
    "        \n",
    "    if len(min_max_scaling_col) > 0:\n",
    "        x_train[min_max_scaling_col] = min_max_scaler.fit_transform(x_train[min_max_scaling_col])\n",
    "        x_test[min_max_scaling_col]  = min_max_scaler.transform(x_test[min_max_scaling_col])\n",
    "        \n",
    "    \n",
    "    # define the variable for onehotencoder\n",
    "    ohe = OneHotEncoder(sparse_output = False, handle_unknown = 'ignore')\n",
    "    \n",
    "    # handel categorical columns if have any\n",
    "    if len(cat_col_x) > 0:\n",
    "        \n",
    "        # encoding cat col and add in data set \n",
    "        x_train[ohe.get_feature_names_out()] = ohe.fit_transform(x_train[cat_col_x])\n",
    "        x_test[ohe.get_feature_names_out()] = ohe.transform(x_test[cat_col_x])\n",
    "        \n",
    "        # drop cat col after encoding it \n",
    "        x_train.drop(columns = cat_col_x, inplace = True)\n",
    "        x_test.drop(columns = cat_col_x, inplace = True)\n",
    "        \n",
    "    # define the object of label encoder\n",
    "    label_enc = LabelEncoder()\n",
    "    \n",
    "    # if y or target column is a categorical columns then using label encoder for values\n",
    "    if problem_type == 'Classification' and y.dtype == 'O':\n",
    "        y_train = label_enc.fit_transform(y_train)\n",
    "        y_test = label_enc.transform(y_test)\n",
    "    \n",
    "    \n",
    "   # found the algoritham that will use to train the moel  \n",
    "    algorithm_df = pd.DataFrame({'Regression':['RandomForestRegressor','DecisionTreeRegressor'],\n",
    "                           'Classification':['RandomForestClassifier','DecisionTreeClassifier']})\n",
    "    \n",
    "    algorithms_list = []\n",
    "    \n",
    "    for algo in algorithm_df[problem_type]:\n",
    "        if dict['design_state_data']['algorithms'][algo]['is_selected']:\n",
    "            algorithms_list.append(algo)\n",
    "        \n",
    "    \n",
    "    # define result df for regression model\n",
    "    result_df = pd.DataFrame({'algoritham':[],\n",
    "                              'r2_train':[],\n",
    "                              'r2_test':[],\n",
    "                              'adj_r2_train':[],\n",
    "                              'adj_r2_test':[],\n",
    "                              'rmse_train':[],\n",
    "                              'rmse_test':[]})\n",
    "    \n",
    "    # train test row and columns\n",
    "    train_n, train_k = x_train.shape\n",
    "    test_n, test_k   = x_test.shape\n",
    "    # for adjusted r2 calculation \n",
    "    \n",
    "    # RandomForestRegressor Model\n",
    "    if 'RandomForestRegressor' in algorithms_list:\n",
    "        \n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "    \n",
    "        # base model define \n",
    "        base_model_rfr = RandomForestRegressor()\n",
    "        \n",
    "        # parmeters values list \n",
    "        n_estimators_list =  pd.Series(np.linspace(dict['design_state_data']['algorithms']['RandomForestRegressor']['min_trees'],\n",
    "                                      dict['design_state_data']['algorithms']['RandomForestRegressor']['max_trees'],4)).astype('int').values\n",
    "        \n",
    "        max_depth_list =  pd.Series(np.linspace(dict['design_state_data']['algorithms']['RandomForestRegressor']['min_depth'],\n",
    "                                      dict['design_state_data']['algorithms']['RandomForestRegressor']['max_depth'],4)).astype('int').values\n",
    "        \n",
    "        \n",
    "        min_samples_leaf_list =  pd.Series(np.linspace(dict['design_state_data']['algorithms']['RandomForestRegressor']['min_samples_per_leaf_min_value'],\n",
    "                                      dict['design_state_data']['algorithms']['RandomForestRegressor']['min_samples_per_leaf_max_value'],4)).astype('int').values\n",
    "        # parameters dict\n",
    "        parameters_rfr = {'n_estimators':n_estimators_list,\n",
    "                     'max_depth':max_depth_list,\n",
    "                     'min_samples_leaf':min_samples_leaf_list}\n",
    "        \n",
    "        # object of GridSearchCV\n",
    "        \n",
    "        grid_search_cv = GridSearchCV(base_model_rfr,parameters_rfr, scoring = 'neg_root_mean_squared_error')\n",
    "        grid_search_cv.fit(x_train,y_train)\n",
    "        best_parm = grid_search_cv.best_params_\n",
    "        \n",
    "        # final modelling using randomforestregressor\n",
    "        model_rfr_f = RandomForestRegressor(n_estimators = best_parm['n_estimators'], max_depth = best_parm['max_depth'],\n",
    "                                           min_samples_leaf = best_parm['min_samples_leaf'])\n",
    "        \n",
    "        # model train\n",
    "        model_rfr_f.fit(x_train,y_train)\n",
    "        \n",
    "        r2_train = r2_score(y_train, model_rfr_f.predict(x_train))\n",
    "        r2_test = r2_score(y_test, model_rfr_f.predict(x_test))\n",
    "        \n",
    "        rmse_train = root_mean_squared_error(y_train, model_rfr_f.predict(x_train))\n",
    "        rmse_test = root_mean_squared_error(y_test, model_rfr_f.predict(x_test))\n",
    "        \n",
    "        adj_r2_train = 1 - (((1-r2_train) *( train_n-1))/(train_n-train_k-1))\n",
    "        adj_r2_test = 1 - (((1-r2_test) *( test_n-1))/(test_n-test_k-1))\n",
    "        \n",
    "        temp_df = pd.DataFrame({'algoritham':['RandomForestRegressor'],\n",
    "                                'r2_train':[r2_train],\n",
    "                                'r2_test':[r2_test],\n",
    "                                'adj_r2_train':[adj_r2_train],\n",
    "                                'adj_r2_test':[adj_r2_test],\n",
    "                                'rmse_train':[rmse_train],\n",
    "                                'rmse_test':[rmse_test]})\n",
    "        \n",
    "        # concat the temp_df with result_df\n",
    "        result_df = pd.concat([result_df, temp_df])\n",
    "        \n",
    "        \n",
    "     # RandomClassifier Model\n",
    "    \n",
    "    if 'RandomForestClassifier' in algorithms_list:\n",
    "        \n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.metrics import classification_report\n",
    "    \n",
    "        # base model define \n",
    "        base_model_rfc = RandomForestClassifier()\n",
    "        \n",
    "        # parmeters values list \n",
    "        n_estimators_list = pd.Series(np.linspace(dict['design_state_data']['algorithms']['RandomForestClassifier']['min_trees'],\n",
    "                                      dict['design_state_data']['algorithms']['RandomForestClassifier']['max_trees'],4)).astype('int').values\n",
    "        \n",
    "        max_depth_list = pd.Series(np.linspace(dict['design_state_data']['algorithms']['RandomForestClassifier']['min_depth'],\n",
    "                                      dict['design_state_data']['algorithms']['RandomForestClassifier']['max_depth'],4)).astype('int').values\n",
    "        \n",
    "        min_samples_leaf_list = pd.Series(np.linspace(dict['design_state_data']['algorithms']['RandomForestClassifier']['min_samples_per_leaf_min_value'],\n",
    "                                      dict['design_state_data']['algorithms']['RandomForestClassifier']['min_samples_per_leaf_max_value'],4)).astype('int').values\n",
    "        # parameters dict\n",
    "        parameters_rfc = {'n_estimators':n_estimators_list,\n",
    "                     'max_depth':max_depth_list,\n",
    "                     'min_samples_leaf':min_samples_leaf_list}\n",
    "        \n",
    "        \n",
    "        # object of GridSearchCV\n",
    "        clf_c = GridSearchCV(base_model_rfc,parameters_rfc, scoring = 'f1_macro')\n",
    "        clf_c.fit(x_train,y_train)\n",
    "        best_parm = clf_c.best_params_\n",
    "        \n",
    "        # final model\n",
    "        model_rfc_f = RandomForestClassifier(n_estimators = best_parm['n_estimators'], max_depth = best_parm['max_depth'],\n",
    "                                           min_samples_leaf = best_parm['min_samples_leaf'])\n",
    "        \n",
    "        # model train\n",
    "        model_rfc_f.fit(x_train,y_train)\n",
    "        \n",
    "        y_pred_train = model_rfc_f.predict(x_train)\n",
    "        y_pred_test = model_rfc_f.predict(x_test)\n",
    "        \n",
    "        print('Randomforest_classifier \\n----------------------------------')\n",
    "        print(f\"Train_report:-- \\n\",classification_report(y_train,y_pred_train))\n",
    "        print(\"\")\n",
    "        print(f\"Test_report:-- \\n\",classification_report(y_test,y_pred_test))\n",
    "        \n",
    "    \n",
    "    # decision tree regressior\n",
    "    if 'DecisionTreeRegressor' in algorithms_list:\n",
    "        \n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "        \n",
    "        # base model define\n",
    "        base_model_dtr = DecisionTreeRegressor()\n",
    "        \n",
    "        # parmeters values list\n",
    "        min_samples_per_leaf_list = dict['design_state_data']['algorithms']['DecisionTreeRegressor']['min_samples_per_leaf']\n",
    "        \n",
    "        max_depth_list =  pd.Series(np.linspace(dict['design_state_data']['algorithms']['DecisionTreeRegressor']['min_depth'],\n",
    "                                      dict['design_state_data']['algorithms']['DecisionTreeRegressor']['max_depth'],4)).astype('int').values \n",
    "        \n",
    "        \n",
    "        splitter_list = []\n",
    "        \n",
    "        if dict['design_state_data']['algorithms']['DecisionTreeRegressor']['use_best']:\n",
    "            splitter_list.append('best')\n",
    "            \n",
    "        \n",
    "        if dict['design_state_data']['algorithms']['DecisionTreeRegressor']['use_random']:\n",
    "            splitter_list.append('random')\n",
    "        \n",
    "        # parameters dict\n",
    "        parameters_dtr = {'splitter':splitter_list,\n",
    "                         'max_depth':max_depth_list,\n",
    "                         'min_samples_leaf':min_samples_per_leaf_list}\n",
    "        \n",
    "        # object of GridSearchCV\n",
    "        clf_dtr = GridSearchCV(base_model_dtr,parameters_dtr, scoring = 'neg_root_mean_squared_error')\n",
    "        clf_dtr.fit(x_train,y_train)\n",
    "        best_parm_dtr = clf_dtr.best_params_\n",
    "        \n",
    "        # final model\n",
    "        model_dtr_final = DecisionTreeRegressor(max_depth = best_parm_dtr['max_depth'],\n",
    "                                           min_samples_leaf = best_parm_dtr['min_samples_leaf'],splitter = best_parm_dtr['splitter'])\n",
    "        \n",
    "        # model train\n",
    "        model_dtr_final.fit(x_train,y_train)\n",
    "        \n",
    "        r2_train = r2_score(y_train, model_dtr_final.predict(x_train))\n",
    "        r2_test = r2_score(y_test, model_dtr_final.predict(x_test))\n",
    "        \n",
    "        rmse_train = root_mean_squared_error(y_train, model_dtr_final.predict(x_train))\n",
    "        rmse_test = root_mean_squared_error(y_test, model_dtr_final.predict(x_test))\n",
    "        \n",
    "        adj_r2_train = 1 - (((1-r2_train) *( train_n-1))/(train_n-train_k-1))\n",
    "        adj_r2_test = 1 - (((1-r2_test) *( test_n-1))/(test_n-test_k-1))\n",
    "        \n",
    "        temp_df = pd.DataFrame({'algoritham':['DecisionTreeRegressor'],\n",
    "                                'r2_train':[r2_train],\n",
    "                                'r2_test':[r2_test],\n",
    "                                'adj_r2_train':[adj_r2_train],\n",
    "                                'adj_r2_test':[adj_r2_test],\n",
    "                                'rmse_train':[rmse_train],\n",
    "                                'rmse_test':[rmse_test]})\n",
    "        \n",
    "        \n",
    "        # concat the temp_df with result_df\n",
    "        result_df = pd.concat([result_df, temp_df])\n",
    "    \n",
    "    # decision tree classsifier\n",
    "    if 'DecisionTreeClassifier' in algorithms_list:\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.metrics import classification_report\n",
    "        \n",
    "        # base model define \n",
    "        base_model_dc = DecisionTreeClassifier()\n",
    "        \n",
    "        # parmeters values list\n",
    "        criteria_list = []\n",
    "        \n",
    "        if dict['design_state_data']['algorithms']['DecisionTreeClassifier']['use_gini']:\n",
    "            criteria_list.append('gini')\n",
    "            \n",
    "        if dict['design_state_data']['algorithms']['DecisionTreeClassifier']['use_entropy']:\n",
    "            criteria_list.append('entropy')\n",
    "        \n",
    "        \n",
    "        splitter_list = []\n",
    "        \n",
    "        if dict['design_state_data']['algorithms']['DecisionTreeClassifier']['use_best']:\n",
    "            splitter_list.append('best')\n",
    "            \n",
    "        \n",
    "        if dict['design_state_data']['algorithms']['DecisionTreeClassifier']['use_random']:\n",
    "            splitter_list.append('random')     \n",
    "        \n",
    "        \n",
    "        min_samples_per_leaf_list = dict['design_state_data']['algorithms']['DecisionTreeClassifier']['min_samples_per_leaf']\n",
    "        \n",
    "        max_depth_list =  pd.Series(np.linspace(dict['design_state_data']['algorithms']['DecisionTreeClassifier']['min_depth'],\n",
    "                                      dict['design_state_data']['algorithms']['DecisionTreeClassifier']['max_depth'],4)).astype('int').values \n",
    "            \n",
    "        # parameters dict\n",
    "        parameters_dc = {'criterion':criteria_list\n",
    "                         ,'splitter':splitter_list,\n",
    "                         'max_depth':max_depth_list,\n",
    "                         'min_samples_leaf':min_samples_per_leaf_list}\n",
    "                     \n",
    "        \n",
    "        # object of GridSearchCV\n",
    "        \n",
    "        clf_dct = GridSearchCV(base_model_dc,parameters_dc, scoring = 'f1_macro')\n",
    "        clf_dct.fit(x_train,y_train)\n",
    "        best_parm_dc = clf_dct.best_params_\n",
    "        \n",
    "        \n",
    "        # final model\n",
    "        model_dct_f = DecisionTreeClassifier(criterion = best_parm_dc['criterion'], max_depth = best_parm_dc['max_depth'],\n",
    "                                           min_samples_leaf = best_parm_dc['min_samples_leaf'],splitter = best_parm_dc['splitter'])\n",
    "        \n",
    "        # model train\n",
    "        model_dct_f.fit(x_train,y_train)\n",
    "        \n",
    "        y_pred_train = model_dct_f.predict(x_train)\n",
    "        y_pred_test = model_dct_f.predict(x_test)\n",
    "        \n",
    "        print('DecisionTreeClassifier \\n----------------------------------')\n",
    "        print(f\"Train_report:-- \")\n",
    "        print(classification_report(y_train,y_pred_train))\n",
    "        print(\"\")\n",
    "        print(f\"Test_report:--\")\n",
    "        print(classification_report(y_test,y_pred_test))\n",
    "\n",
    "        \n",
    "    # return result df if regression problem\n",
    "    if problem_type == 'Regression':\n",
    "        return result_df\n",
    "    \n",
    "                         \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b40f025-0ce2-4c43-b341-046b2ee52b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomforest_classifier \n",
      "----------------------------------\n",
      "Train_report:-- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       0.97      0.89      0.93        37\n",
      "           2       0.91      0.98      0.94        43\n",
      "\n",
      "    accuracy                           0.96       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.96      0.96      0.96       120\n",
      "\n",
      "\n",
      "Test_report:-- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.85      0.92        13\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.95      0.93        30\n",
      "weighted avg       0.95      0.93      0.93        30\n",
      "\n",
      "DecisionTreeClassifier \n",
      "----------------------------------\n",
      "Train_report:-- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       0.97      0.89      0.93        37\n",
      "           2       0.91      0.98      0.94        43\n",
      "\n",
      "    accuracy                           0.96       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.96      0.96      0.96       120\n",
      "\n",
      "\n",
      "Test_report:--\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.85      0.92        13\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.95      0.93        30\n",
      "weighted avg       0.95      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "automated_modelling('algoparams_from_ui1.json.rtf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e2acc-000f-4428-ae10-48033e6cf210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
